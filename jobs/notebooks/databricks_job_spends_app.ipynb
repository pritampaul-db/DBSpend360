{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d47305c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta, timezone\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import Row\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7136f8e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(\"TotalJobSpendsReporter\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392b7735",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "dbutils.widgets.text(\"catalog\", \"\", \"CATALOG\")\n",
    "dbutils.widgets.text(\"schema\", \"\", \"SCHEMA\")\n",
    "dbutils.widgets.text(\"overlap_days\", \"3\", \"Overlap days (min 2)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b3e3bc",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "catalog = dbutils.widgets.get(\"catalog\")\n",
    "schema = dbutils.widgets.get(\"schema\")\n",
    "overlap_days = int(dbutils.widgets.get(\"overlap_days\") or \"2\")\n",
    "\n",
    "if overlap_days < 2:\n",
    "    logger.warning(\"overlap_days < 2; forcing to 2 for cost convergence best practice.\")\n",
    "    overlap_days = 2\n",
    "\n",
    "audit_table          = f\"{catalog}.{schema}.dbspend360_audit_log\"\n",
    "cloud_cost_table     = f\"{catalog}.{schema}.dbspend360_cloud_cost_explorer\"\n",
    "databricks_cost_table= f\"{catalog}.{schema}.dbspend360_dbu_cost\"\n",
    "total_job_spends_table = f\"{catalog}.{schema}.dbspend360_total_job_spends\"\n",
    "error_log_table      = f\"{catalog}.{schema}.dbspend360_error_log\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da62dffc",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# =======================================================\n",
    "# Total Job Spends Client\n",
    "# =======================================================\n",
    "class TotalJobSpendsClient:\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        audit_table: str,\n",
    "        cloud_cost_table: str,\n",
    "        databricks_cost_table: str,\n",
    "        total_job_spends_table: str,\n",
    "        error_log_table: str,\n",
    "        overlap_days: int,\n",
    "    ):\n",
    "        self.audit_table = audit_table\n",
    "        self.cloud_cost_table = cloud_cost_table\n",
    "        self.databricks_cost_table = databricks_cost_table\n",
    "        self.total_job_spends_table = total_job_spends_table\n",
    "        self.error_log_table = error_log_table\n",
    "        self.overlap_days = overlap_days\n",
    "\n",
    "    def _get_date_window(self):\n",
    "        wm = (\n",
    "            spark.table(self.audit_table)\n",
    "                 .filter(\"table_name = 'dbspend360_total_job_spends' AND status = 'SUCCESS'\")\n",
    "        )\n",
    "\n",
    "        if wm.limit(1).count() == 0:\n",
    "            last_end_date = datetime.now(timezone.utc).date() - timedelta(days=365 - self.overlap_days)\n",
    "        else:\n",
    "            last_end_date = wm.agg(F.max(\"end_date\")).collect()[0][0]\n",
    "\n",
    "        start_dt = last_end_date - timedelta(days=self.overlap_days - 1)\n",
    "        end_dt = datetime.now(timezone.utc).date()\n",
    "        return start_dt, end_dt\n",
    "\n",
    "    def _log_run(self, start_dt, end_dt, status, row_count, message=\"\"):\n",
    "        run_log_df = spark.createDataFrame([\n",
    "            Row(\n",
    "                table_name=\"dbspend360_total_job_spends\",\n",
    "                start_date=start_dt,\n",
    "                end_date=end_dt,\n",
    "                status=status,\n",
    "                row_count=int(row_count),\n",
    "                message=message,\n",
    "                created_at=datetime.now(timezone.utc)\n",
    "            )\n",
    "        ])\n",
    "        run_log_df.write.mode(\"append\").insertInto(self.audit_table)\n",
    "\n",
    "    def _log_errors(self, dbu_df, cloud_df):\n",
    "        # DBU without cloud cost\n",
    "        dbu_only = (\n",
    "            dbu_df.alias(\"d\")\n",
    "            .join(\n",
    "                cloud_df.alias(\"a\"),\n",
    "                on=(\n",
    "                    (F.col(\"d.cluster_id\") == F.col(\"a.cluster_id\")) &\n",
    "                    (F.col(\"d.usage_date\") == F.col(\"a.cost_incurred_date\"))\n",
    "                ),\n",
    "                how=\"left_anti\"\n",
    "            )\n",
    "        )\n",
    "\n",
    "        if not dbu_only.isEmpty():\n",
    "            dbu_err = (\n",
    "                dbu_only\n",
    "                .select(\n",
    "                    F.lit(\"DBR_DBU\").alias(\"source_system\"),\n",
    "                    F.lit(\"NO_MATCH_cloud_COST\").alias(\"error_type\"),\n",
    "                    F.col(\"d.cluster_id\").alias(\"cluster_id\"),\n",
    "                    \"job_id\",\n",
    "                    \"run_id\",\n",
    "                    \"usage_date\",\n",
    "                    F.col(\"d.currency\").alias(\"currency\"),\n",
    "                    F.lit(\"No matching cloud VM cost row for this DBU usage\").alias(\"error_detail\"),\n",
    "                    F.to_json(F.struct(\"d.*\")).alias(\"raw_record\"),\n",
    "                )\n",
    "                .withColumn(\"created_at\", F.lit(datetime.now(timezone.utc)))\n",
    "            )\n",
    "\n",
    "            dbu_err.write.mode(\"append\").insertInto(self.error_log_table)\n",
    "\n",
    "        # cloud without DBU cost\n",
    "        cloud_only = (\n",
    "            cloud_df.alias(\"a\")\n",
    "            .join(\n",
    "                dbu_df.alias(\"d\"),\n",
    "                on=(\n",
    "                    (F.col(\"a.cluster_id\") == F.col(\"d.cluster_id\")) &\n",
    "                    (F.col(\"a.cost_incurred_date\") == F.col(\"d.usage_date\"))\n",
    "                ),\n",
    "                how=\"left_anti\"\n",
    "            )\n",
    "        )\n",
    "\n",
    "        if not cloud_only.isEmpty():\n",
    "            cloud_err = (\n",
    "                cloud_only\n",
    "                .select(\n",
    "                    F.lit(\"cloud_COST\").alias(\"source_system\"),\n",
    "                    F.lit(\"NO_MATCH_DBR_DBU\").alias(\"error_type\"),\n",
    "                    F.col(\"a.cluster_id\").alias(\"cluster_id\"),\n",
    "                    F.lit(None).cast(\"string\").alias(\"job_id\"),\n",
    "                    F.lit(None).cast(\"string\").alias(\"run_id\"),\n",
    "                    F.lit(None).cast(\"date\").alias(\"usage_date\"),\n",
    "                    F.col(\"a.currency\").alias(\"currency\"),\n",
    "                    F.lit(\"No matching DBR DBU cost row for this cloud VM cost\").alias(\"error_detail\"),\n",
    "                    F.to_json(F.struct(\"a.*\")).alias(\"raw_record\"),\n",
    "                )\n",
    "                .withColumn(\"created_at\", F.lit(datetime.now(timezone.utc)))\n",
    "            )\n",
    "\n",
    "            cloud_err.write.mode(\"append\").insertInto(self.error_log_table)\n",
    "\n",
    "    def build_total_job_spends(self):\n",
    "        start_dt, end_dt = self._get_date_window()\n",
    "\n",
    "        if start_dt > end_dt:\n",
    "            message = f\"Invalid date window: start_dt={start_dt} > end_dt={end_dt}.\"\n",
    "            logger.error(message)\n",
    "            self._log_run(start_dt, end_dt, \"FAILED\", 0, message)\n",
    "            dbutils.notebook.exit(\"FAILED: Invalid date window.\")\n",
    "\n",
    "        logger.info(f\"Building dbspend360_total_job_spends for {start_dt} → {end_dt}\")\n",
    "\n",
    "        cloud_df = (spark.table(self.cloud_cost_table)\n",
    "                        .alias(\"cc\")\n",
    "                        .filter(\n",
    "                                (F.col(\"cost_incurred_date\") >= F.lit(start_dt)) &\n",
    "                                (F.col(\"cost_incurred_date\") <= F.lit(end_dt))\n",
    "                            )\n",
    "        )\n",
    "        dbu_df = (\n",
    "            spark.table(self.databricks_cost_table)\n",
    "                 .alias(\"dbu\")\n",
    "                 .filter(\n",
    "                     (F.col(\"usage_date\") >= F.lit(start_dt)) &\n",
    "                     (F.col(\"usage_date\") <= F.lit(end_dt))\n",
    "                 )\n",
    "        )\n",
    "\n",
    "        if dbu_df.limit(1).count() == 0:\n",
    "            logger.info(\"No DBU rows in this date window; nothing to join.\")\n",
    "            self._log_run(start_dt, end_dt, \"SUCCESS\", 0, \"No DBU data in window\")\n",
    "            return\n",
    "\n",
    "        joined = dbu_df.join(\n",
    "            cloud_df,\n",
    "            on=(\n",
    "                (dbu_df[\"cluster_id\"] == cloud_df[\"cluster_id\"]) &\n",
    "                (dbu_df[\"usage_date\"] == cloud_df[\"cost_incurred_date\"])\n",
    "            ),\n",
    "            how=\"inner\"\n",
    "        )\n",
    "\n",
    "        joined = joined.withColumn(\n",
    "            \"final_currency\",\n",
    "            F.coalesce(F.col(\"dbu.currency\"), F.col(\"cc.currency\"))\n",
    "        )\n",
    "\n",
    "        joined = joined.withColumn(\n",
    "            \"cloud_cost\",\n",
    "            F.col(\"cc.cloud_cost\")\n",
    "        )\n",
    "\n",
    "        final_df = (\n",
    "            joined\n",
    "            .select(\n",
    "                F.col(\"dbu.cluster_id\").alias(\"cluster_id\"),\n",
    "                \"job_id\",\n",
    "                \"run_id\",\n",
    "                \"usage_date\",\n",
    "                F.col(\"cloud_cost\").alias(\"cloud_cost\"),\n",
    "                F.col(\"databricks_cost\"),\n",
    "                F.col(\"final_currency\").alias(\"currency\")\n",
    "            )\n",
    "        )\n",
    "\n",
    "        final_df = (\n",
    "            final_df\n",
    "            .withColumn(\"total_cost\", F.col(\"cloud_cost\") + F.col(\"databricks_cost\"))\n",
    "            .withColumn(\"created_at\", F.current_timestamp())\n",
    "            .withColumn(\"updated_at\", F.current_timestamp())\n",
    "        )\n",
    "\n",
    "        final_df.createOrReplaceTempView(\"job_spends_inc\")\n",
    "        row_count = final_df.count()\n",
    "\n",
    "        spark.sql(f\"\"\"\n",
    "        MERGE INTO {self.total_job_spends_table} AS t\n",
    "        USING job_spends_inc AS s\n",
    "        ON  t.cluster_id = s.cluster_id\n",
    "        AND t.job_id     = s.job_id\n",
    "        AND t.run_id     = s.run_id\n",
    "        AND t.usage_date = s.usage_date\n",
    "        WHEN MATCHED THEN\n",
    "          UPDATE SET\n",
    "            t.cloud_cost      = s.cloud_cost,\n",
    "            t.databricks_cost = s.databricks_cost,\n",
    "            t.total_cost      = s.total_cost,\n",
    "            t.updated_at      = current_timestamp()\n",
    "        WHEN NOT MATCHED THEN\n",
    "          INSERT (cluster_id, job_id, run_id, usage_date,\n",
    "                  cloud_cost, databricks_cost, currency,\n",
    "                  total_cost, created_at, updated_at)\n",
    "          VALUES (s.cluster_id, s.job_id, s.run_id, s.usage_date,\n",
    "                  s.cloud_cost, s.databricks_cost, s.currency,\n",
    "                  s.total_cost, current_timestamp(), current_timestamp());\n",
    "        \"\"\")\n",
    "\n",
    "        # Error logging (DBU-only and cloud-only)\n",
    "        self._log_errors(dbu_df, cloud_df)\n",
    "\n",
    "        # Run log\n",
    "        self._log_run(start_dt, end_dt, \"SUCCESS\", row_count, \"\")\n",
    "        logger.info(f\"Merged {row_count} rows into {self.total_job_spends_table} for {start_dt} → {end_dt}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f395eaed",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# =======================================================\n",
    "# APP\n",
    "# =======================================================\n",
    "class TotalJobSpendsApp:\n",
    "\n",
    "    def __init__(self):\n",
    "        catalog = dbutils.widgets.get(\"catalog\")\n",
    "        schema = dbutils.widgets.get(\"schema\")\n",
    "        overlap_days = int(dbutils.widgets.get(\"overlap_days\") or \"2\")\n",
    "\n",
    "        if overlap_days < 2:\n",
    "            logger.warning(\"overlap_days < 2; forcing to 2 for cost convergence best practice.\")\n",
    "            overlap_days = 2\n",
    "\n",
    "        audit_table           = f\"{catalog}.{schema}.dbspend360_audit_log\"\n",
    "        cloud_cost_table      = f\"{catalog}.{schema}.dbspend360_cloud_cost_explorer\"\n",
    "        databricks_cost_table = f\"{catalog}.{schema}.dbspend360_dbu_cost\"\n",
    "        total_job_spends_table= f\"{catalog}.{schema}.dbspend360_total_job_spends\"\n",
    "        error_log_table       = f\"{catalog}.{schema}.dbspend360_error_log\"\n",
    "\n",
    "        self.client = TotalJobSpendsClient(\n",
    "            audit_table=audit_table,\n",
    "            cloud_cost_table=cloud_cost_table,\n",
    "            databricks_cost_table=databricks_cost_table,\n",
    "            total_job_spends_table=total_job_spends_table,\n",
    "            error_log_table=error_log_table,\n",
    "            overlap_days=overlap_days,\n",
    "        )\n",
    "\n",
    "    def run(self):\n",
    "        self.client.build_total_job_spends()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d6819d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# =======================================================\n",
    "# Execute\n",
    "# =======================================================\n",
    "app = TotalJobSpendsApp()\n",
    "app.run()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
